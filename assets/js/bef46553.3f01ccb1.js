"use strict";(globalThis.webpackChunkbrain=globalThis.webpackChunkbrain||[]).push([[7393],{722:(n,e,s)=>{s.r(e),s.d(e,{assets:()=>t,contentTitle:()=>d,default:()=>a,frontMatter:()=>c,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"*Private/Central Analytics/Archive/RIL Flink Application Review- UnionInventory and Upstream Sources","title":"RIL Flink Application Review- UnionInventory and Upstream Sources","description":"Source App Summaries and Inferences","source":"@site/docs/*Private/Central Analytics/Archive/RIL Flink Application Review- UnionInventory and Upstream Sources.md","sourceDirName":"*Private/Central Analytics/Archive","slug":"/*Private/Central Analytics/Archive/RIL Flink Application Review- UnionInventory and Upstream Sources","permalink":"/*Private/Central Analytics/Archive/RIL Flink Application Review- UnionInventory and Upstream Sources","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}}');var r=s(4848),l=s(8453);const c={},d=void 0,t={},o=[{value:"<strong>Source App Summaries and Inferences</strong>",id:"source-app-summaries-and-inferences",level:3},{value:"<strong>1. RPOS</strong>",id:"1-rpos",level:3},{value:"<strong>2. ROMS</strong>",id:"2-roms",level:3},{value:"<strong>3. MSEG</strong>",id:"3-mseg",level:3},{value:"<strong>MARD</strong>",id:"mard",level:3},{value:"<strong>UnionInventory Source-Sink Notes</strong>",id:"unioninventory-source-sink-notes",level:3},{value:"Summary for Issues in UnionInventory",id:"summary-for-issues-in-unioninventory",level:3},{value:"<strong>About omission of PK in Flink Tables Removes Changelog Semantics</strong>",id:"about-omission-of-pk-in-flink-tables-removes-changelog-semantics",level:3}];function h(n){const e={code:"code",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.h3,{id:"source-app-summaries-and-inferences",children:(0,r.jsx)(e.strong,{children:"Source App Summaries and Inferences"})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"1-rpos",children:(0,r.jsx)(e.strong,{children:"1. RPOS"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Aggregates per ",(0,r.jsx)(e.code,{children:"(SITE, ARTICLE, SALE_DATE)"})]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["Sink: ",(0,r.jsx)(e.code,{children:"CONFLUENT_SALES_ARTICLE"})," via ",(0,r.jsx)(e.strong,{children:"upsert-Kafka"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Inference"}),": Stream of sales transactions"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Notes:"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["DDL for ",(0,r.jsx)(e.code,{children:"CONFLUENT_SITE_ARTICLE_TICKET"})," contains line \u201cCASE WHEN B.op_type = 'U' THEN B.QUANTITY ELSE 0 END AS QUANTITY_U\u201d but ",(0,r.jsx)(e.code,{children:"Filtered_TXNITEM"})," already has \u201cWHERE ... AND op_type = 'I'\u201d. So ",(0,r.jsx)(e.code,{children:"B.op_type = 'U'"})," will ",(0,r.jsx)(e.strong,{children:"never match"}),", making this field ",(0,r.jsx)(e.strong,{children:"always zero"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Either:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Remove ",(0,r.jsx)(e.code,{children:"QUANTITY_U"})," altogether."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Or\u2014if planning to relax the ",(0,r.jsx)(e.code,{children:"op_type"})," filter in future\u2014make a note but comment it out for now."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["You are calling ",(0,r.jsx)(e.code,{children:"TO_TIMESTAMP()"})," on a string column (",(0,r.jsx)(e.code,{children:"A_SALE_DELTA_DATE"}),") ",(0,r.jsx)(e.strong,{children:"inside a"})," ",(0,r.jsx)(e.code,{children:"**WHERE**"})," ",(0,r.jsx)(e.strong,{children:"clause before aggregation"}),"."]}),"\n",(0,r.jsxs)(e.p,{children:["That function must: Parse the string for ",(0,r.jsx)(e.strong,{children:"every incoming record"})]}),"\n",(0,r.jsx)(e.p,{children:"Noted that the pipeline does:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"op_ts \u2192 string"})," (via ",(0,r.jsx)(e.code,{children:"DATE_FORMAT"}),")"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"string \u2192 timestamp"})," (via ",(0,r.jsx)(e.code,{children:"TO_TIMESTAMP"}),")"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Then filters on the timestamp"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Recommendation"})}),"\n",(0,r.jsx)(e.p,{children:"Avoid converting timestamp \u2192 string \u2192 timestamp again"}),"\n",(0,r.jsxs)(e.p,{children:["In your first SELECT (i.e., enrichment query into ",(0,r.jsx)(e.code,{children:"CONFLUENT_SITE_ARTICLE_TICKET"}),"), change this:"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-SQL",children:"DATE_FORMAT(A.op_ts, 'yyyyMMddHHmmss') AS A_SALE_DELTA_DATE,\n"})}),"\n",(0,r.jsx)(e.p,{children:"to:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-SQL",children:"A.op_ts AS A_SALE_DELTA_TS,\nDATE_FORMAT(A.op_ts, 'yyyyMMddHHmmss') AS A_SALE_DELTA_DATE,\n"})}),"\n",(0,r.jsxs)(e.p,{children:["Similarly for ",(0,r.jsx)(e.code,{children:"B.op_ts \u2192 B_SALE_DELTA_TS"})," and ",(0,r.jsx)(e.code,{children:"B_SALE_DELTA_DATE"}),"."]}),"\n",(0,r.jsxs)(e.p,{children:["Then in your aggregation query (insert into ",(0,r.jsx)(e.code,{children:"CONFLUENT_SALES_ARTICLE"}),"), change:"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-SQL",children:"TO_TIMESTAMP(A_SALE_DELTA_DATE, 'yyyyMMddHHmmss') >= CURRENT_DATE\n"})}),"\n",(0,r.jsx)(e.p,{children:"to:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-SQL",children:"A_SALE_DELTA_TS >= CURRENT_DATE\n"})}),"\n",(0,r.jsx)(e.p,{children:"This avoids unnecessary parsing."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"2-roms",children:(0,r.jsx)(e.strong,{children:"2. ROMS"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Aggregates per ",(0,r.jsx)(e.code,{children:"(STORENO, ARTICLEID, ORDERDATE)"})]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["Sink: ",(0,r.jsx)(e.code,{children:"EXPSTORE_ORDER_AGGREGATED"})," via ",(0,r.jsx)(e.strong,{children:"upsert-Kafka"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Inference"}),": Stream of orders information"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Implication"}),": Since filtering is on recent 15 days and then aggregated by ",(0,r.jsx)(e.code,{children:"(SITE, ARTICLE)"}),", defining PK ",(0,r.jsx)(e.code,{children:"(STORENO, ARTICLEID, ORDERDATE)"})," is needed to enable updates. However, the UNION logic further aggregates by ",(0,r.jsx)(e.code,{children:"(SITE, ARTICLE)"}),", which is valid as long as filtering ensures no duplicate dates."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"3-mseg",children:(0,r.jsx)(e.strong,{children:"3. MSEG"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Aggregates per ",(0,r.jsx)(e.code,{children:"(MATNR, WERKS, op_date)"})]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["Sink: ",(0,r.jsx)(e.code,{children:"MSEG_FINAL"})," via ",(0,r.jsx)(e.strong,{children:"upsert-Kafka"})," on ",(0,r.jsx)(e.code,{children:"(MATNR, WERKS, op_date_str)"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Inference"}),": Changelog stream capturing changes ( delta ) in inventory per MARD cycle"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Implication"}),": Must define PK as ",(0,r.jsx)(e.code,{children:"(MATNR, WERKS, op_date)"})," in the Flink table. Filtering on ",(0,r.jsx)(e.code,{children:"op_date_str = CURRENT_DATE"})," ensures only ",(0,r.jsx)(e.strong,{children:"one record per key"})," enters the aggregation, enabling accurate group-by ",(0,r.jsx)(e.code,{children:"(SITE, ARTICLE)"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"mard",children:(0,r.jsx)(e.strong,{children:"MARD"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Uses ROWNUM to deduplicate record over ",(0,r.jsx)(e.code,{children:"(MBLNR, MJAHR, ZEILE)"})]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Inference: Stream of latest material stock state"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Combines full + delta"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Sink: ",(0,r.jsx)(e.code,{children:"MARD_FINAL"})," via upsert-",(0,r.jsx)(e.strong,{children:"Kafka"})," on ",(0,r.jsx)(e.strong,{children:"("}),(0,r.jsx)(e.code,{children:"MATNR, WERKS"}),")"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Inference"}),": This is an update stream, representing current stock data per day"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Implication"}),": In ",(0,r.jsx)(e.code,{children:"unioninventory"}),", any aggregation downstream (e.g., per ",(0,r.jsx)(e.code,{children:"SITE, ARTICLE"}),") will correctly retract old values and apply updated values."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"unioninventory-source-sink-notes",children:(0,r.jsx)(e.strong,{children:"UnionInventory Source-Sink Notes"})}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"RPOS ("}),(0,r.jsx)(e.code,{children:"**CONFLUENT_SALES_ARTICLE**"}),(0,r.jsx)(e.strong,{children:")"})]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Upstream source is ",(0,r.jsx)(e.code,{children:"upsert-kafka"})," with PK. Kafka topic key ",(0,r.jsx)(e.code,{children:"(SITE, ARTICLE, SALE_DATE)"})]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Source in ",(0,r.jsx)(e.code,{children:"unionInventory"})," is treated as changelog stream / append-only \u2192 ==PK not defined=="]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Note:"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"It would be reasonable to read as upsert with PK defined in the source topic"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"ROMS ("}),(0,r.jsx)(e.code,{children:"**EXPSTORE_ORDER_AGGREGATED**"}),(0,r.jsx)(e.strong,{children:")"})]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Upstream source is ",(0,r.jsx)(e.code,{children:"upsert-kafka"}),". Kafka topic key ",(0,r.jsx)(e.code,{children:"(STORENO, ARTICLEID, ORDERDATE)"})]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Source in ",(0,r.jsx)(e.code,{children:"unionInventory"})," is treated as changelog stream / append-only \u2192 ==PK not defined=="]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["In ",(0,r.jsx)(e.code,{children:"unionInventory"}),", filtered on recent 15 days and then aggregated by ",(0,r.jsx)(e.code,{children:"(SITE, ARTICLE)"})]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Note:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["It would be reasonable to read as upsert with PK defined on ",(0,r.jsx)(e.code,{children:"(STORENO, ARTICLEID)"})," to read as upsert stream."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"MSEG ("}),(0,r.jsx)(e.code,{children:"**CONFLUENT_MSEG_FINAL**"}),(0,r.jsx)(e.strong,{children:")"})]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Upstream source is ",(0,r.jsx)(e.code,{children:"upsert-kafka"}),".Aggregated per ",(0,r.jsx)(e.code,{children:"(MATNR, WERKS, op_date_str)"})]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Source in ",(0,r.jsx)(e.code,{children:"unionInventory"})," is treated as changelog stream / append-only \u2192 ==PK not defined=="]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Note:"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"It would be reasonable to read as upsert with PK defined in the source topic"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"MARD ("}),(0,r.jsx)(e.code,{children:"**CONFLUENT_MARD_FINAL**"}),(0,r.jsx)(e.strong,{children:")"})]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Upstream source is ",(0,r.jsx)(e.code,{children:"upsert-kafka"}),". Deduplicates on ",(0,r.jsx)(e.code,{children:"(MATNR, WERKS)"})]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Source in ",(0,r.jsx)(e.code,{children:"unionInventory"})," is treated as changelog stream / append-only \u2192 ==PK not defined=="]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Note:"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"It would be reasonable to read as upsert with PK defined in the source topic"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Milkbasket ("}),(0,r.jsx)(e.code,{children:"**CONFLUENT_2**"}),(0,r.jsx)(e.strong,{children:")"})]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Source in ",(0,r.jsx)(e.code,{children:"unionInventory"})," is treated as upsert-stream over \u2192 PK ",(0,r.jsx)(e.code,{children:"(SITE, ARTICLE, ORDER_DATE)"})]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["PK defined and matched in ",(0,r.jsx)(e.code,{children:"unionInventory"})]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"summary-for-issues-in-unioninventory",children:"Summary for Issues in UnionInventory"}),"\n",(0,r.jsxs)(e.p,{children:["The ",(0,r.jsx)(e.code,{children:"UnionInventory"})," Flink SQL application performs an aggregation over multiple Kafka sources\u2014each feeding data ( inventory, sales/orders, or movement deltas )\u2014to compute the latest inventory view per ",(0,r.jsx)(e.code,{children:"(SITE, ARTICLE)"}),"."]}),"\n",(0,r.jsxs)(e.p,{children:["The correctness of this aggregation depends on ",(0,r.jsx)(e.strong,{children:"changelog tracking"})," (detecting ",(0,r.jsx)(e.code,{children:"+U"}),", ",(0,r.jsx)(e.code,{children:"-U"})," updates) from upstream Kafka sources. This, in turn, depends on:"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Whether the source Kafka topics are written using ",(0,r.jsx)(e.strong,{children:"upsert semantics"})]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"I see this is correctly defined in individual apps"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Whether the ",(0,r.jsx)(e.strong,{children:"primary keys"})," are ",(0,r.jsx)(e.strong,{children:"correctly defined"})," on the consuming Flink tables"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"This is not defined in UnionInventory"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"RPOS, MSEG, MARD are treated as append-only"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"This can lead to double counting if (SITE,ARTICLE) aggregation in individual applications is updated"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["Read \u201c",(0,r.jsx)(e.strong,{children:"About omission of PK in Flink Tables Removes Changelog Semantics\u201d"})," section for example sceanrio"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Whether the ",(0,r.jsx)(e.strong,{children:"downstream grouping keys match"})," the update keys of the upstream streams"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["source table has PK ",(0,r.jsx)(e.code,{children:"(A, B, C)"})," and aggregation is on ",(0,r.jsx)(e.code,{children:"(A, B)"}),":"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Issue example scenario:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Initial state was set to 10 by +I from the upsert source A"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"A -U, +U sequence from the upsert stream A ( for the same SITE, ARTICLE, DATE ) updated the state to 15 ( = 10 -10 + 15 )"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"A subsequent +I event ( emitted when the DATE changed while SITE, ARTICLE were same ) from the same upsert source A added 20, increasing the state to 35."}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"This implies that when the upstream key is a superset of the GROUP BY columns, the downstream operator may treat events as additive instead of updates."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Aggregation state is maintained per"})," ",(0,r.jsx)(e.code,{children:"**(SITE, ARTICLE)**"})," But upstream changelog tracks state per ",(0,r.jsx)(e.code,{children:"(SITE, ARTICLE, DATE)"})]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Therefore, Flink sees each new ",(0,r.jsx)(e.code,{children:"DATE"})," as a new, independent record, and treats it as an append / insert"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"This causes accumulation, not update, and may result in overcounting"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"about-omission-of-pk-in-flink-tables-removes-changelog-semantics",children:(0,r.jsx)(e.strong,{children:"About omission of PK in Flink Tables Removes Changelog Semantics"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["If a Flink table does ",(0,r.jsx)(e.strong,{children:"not"})," define a ",(0,r.jsx)(e.code,{children:"PRIMARY KEY"})," ( even if the Kafka topic has keys and comes from an upsert-Kafka producer ), Flink ",(0,r.jsx)(e.strong,{children:"treats the table as append-only"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"That causes:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Double-counting in aggregations"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Missed retractions or corrections"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Example"}),"\n",(0,r.jsxs)(e.p,{children:["Say ",(0,r.jsx)(e.code,{children:"CONFLUENT_MSEG_FINAL"})," topic being written to by upsert-kafka producers as follows:"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-JSON",children:'Key: { "id": 123 }\nValue (first): { "id": 123, "count": 10 }\nValue (second): { "id": 123, "count": 20 }\n'})}),"\n",(0,r.jsx)(e.p,{children:"If table is defined as:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-SQL",children:"CREATE TABLE my_table (\n  id STRING,\n  count INT,\n  PRIMARY KEY (id) NOT ENFORCED\n) WITH (\n  'connector' = 'upsert-kafka',\n  ...\n);\n"})}),"\n",(0,r.jsx)(e.p,{children:"Then Flink processes the above as:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.code,{children:"+I(id=123, count=10)"})}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.code,{children:"-U(id=123, count=10)"})}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.code,{children:"+U(id=123, count=20)"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"But if you omit the PK, like:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-SQL",children:"CREATE TABLE my_table (\n  id STRING,\n  count INT\n) WITH (\n  'connector' = 'kafka',\n  ...\n);\n"})}),"\n",(0,r.jsx)(e.p,{children:"Then Flink assumes append-only, so the second event is just another insert:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.code,{children:"+I(id=123, count=10)"})}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.code,{children:"+I(id=123, count=20)"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"The downstream aggregation operator in unionInventory tracks correct state using the retracting events, else the state will hold wrong values."}),"\n",(0,r.jsx)(e.p,{children:"In this case, SUM aggregate would consider (10+20) as MSEGs contribution, however we wanted it to consider (-10+20)"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Fix"}),": Define the same PK as in the upstream source app"]}),"\n"]}),"\n"]})]})}function a(n={}){const{wrapper:e}={...(0,l.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(h,{...n})}):h(n)}},8453:(n,e,s)=>{s.d(e,{R:()=>c,x:()=>d});var i=s(6540);const r={},l=i.createContext(r);function c(n){const e=i.useContext(l);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function d(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:c(n.components),i.createElement(l.Provider,{value:e},n.children)}}}]);