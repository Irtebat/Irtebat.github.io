"use strict";(globalThis.webpackChunkbrain=globalThis.webpackChunkbrain||[]).push([[4146],{4236:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>d,frontMatter:()=>l,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"*Private/JioStar/Issue with Flink Job","title":"Issue with Flink Job","description":"Date: 20/1/26","source":"@site/docs/*Private/JioStar/Issue with Flink Job.md","sourceDirName":"*Private/JioStar","slug":"/*Private/JioStar/Issue with Flink Job","permalink":"/*Private/JioStar/Issue with Flink Job","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}}');var r=i(4848),t=i(8453);const l={},o=void 0,c={},a=[{value:"Checklist",id:"checklist",level:4},{value:"Summary",id:"summary",level:4}];function h(e){const n={br:"br",code:"code",em:"em",h4:"h4",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:(0,r.jsx)(n.em,{children:"Date: 20/1/26"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Observed"}),(0,r.jsx)(n.br,{}),"\n","Flink Job ( Kafka Sink )"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"flink version 1.13.1"}),"\n",(0,r.jsxs)(n.li,{children:["flink-connector-kafka 2.11\nSink parallelism is 60; topic partition count is 100.\nJob becomes unresponsive after publishing ~4 mil messages",(0,r.jsx)(n.br,{}),"\n","Effective batching is low ( ~3 ).",(0,r.jsx)(n.br,{}),"\n","Total ingress is not close to cluster limit.",(0,r.jsx)(n.br,{}),"\n","No evidence of produce throttling or hot partitions.",(0,r.jsx)(n.br,{}),"\n","High request-latency-avg",(0,r.jsx)(n.br,{}),"\n","High record-queue-time-avg",(0,r.jsx)(n.br,{}),"\n","Low / zero bufferpool-wait-time-total",(0,r.jsx)(n.br,{}),"\n","TaskManagers are not being killed; the job restarts (failure detected by Flink runtime rather than platform OOM/eviction)."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"What we have ruled out so far"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Ingress quota / throughput limit on the cluster as the primary cause (total ingress below 1200 MB/s)."}),"\n",(0,r.jsx)(n.li,{children:"Broker-side produce throttling."}),"\n",(0,r.jsx)(n.li,{children:"Hot partitions / partition skew."}),"\n",(0,r.jsx)(n.li,{children:"Producers are not blocked on buffer memory allocation"}),"\n",(0,r.jsx)(n.li,{children:"TaskManager kill / container eviction (job restarts are driven by Flink failure handling)."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Most likely cause"}),(0,r.jsx)(n.br,{}),"\n","Request-latency-avg rises, record-queue-time-avg rises, checkpoints slow, causing sustained backpressure and eventual restart via timeouts",(0,r.jsx)(n.br,{}),"\n","To check:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"checkpoint timeouts"}),"\n",(0,r.jsx)(n.li,{children:"embedded Kafka producer\u2019s send/delivery/request timeouts"}),"\n",(0,r.jsx)(n.li,{children:"transaction-related timeouts"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.em,{children:"Date: 21/1/26"})}),"\n",(0,r.jsx)(n.h4,{id:"checklist",children:"Checklist"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Kafka producer behavior (sink-side)"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Enable DEBUG logs for:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"org.apache.kafka.clients.producer"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"org.apache.kafka.clients.NetworkClient"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Verify runtime producer configs:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"acks"})}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"linger.ms"}),", ",(0,r.jsx)(n.code,{children:"batch.size"})]}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"delivery.timeout.ms"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"request.timeout.ms"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"max.in.flight.requests.per.connection"})}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"retries"})," and ",(0,r.jsx)(n.code,{children:"retry.backoff.ms"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Checkpointing (Flink-level)"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Flink UI \u2192 ",(0,r.jsx)(n.strong,{children:"Checkpoints"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Look for ",(0,r.jsx)(n.strong,{children:"increasing duration"})," and ",(0,r.jsx)(n.strong,{children:"timeouts"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Identify whether failures point to the ",(0,r.jsx)(n.strong,{children:"Kafka sink operator"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Check JobManager logs for:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"Checkpoint expired"}),", ",(0,r.jsx)(n.code,{children:"Declined checkpoint"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Confirm configs:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"execution.checkpointing.timeout"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"execution.checkpointing.interval"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Transactions / EOS (if exactly-once is enabled)"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Verify:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"transaction.timeout.ms"})," > worst-case checkpoint duration (with buffer)."]}),"\n",(0,r.jsx)(n.li,{children:"Broker max transaction timeout is not exceeded."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Look for fatal producer errors:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Transaction timeout"}),"\n",(0,r.jsx)(n.li,{children:"Producer fenced / aborted transactions"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Correlate:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Rising checkpoint time \u2192 transaction duration \u2192 job restart."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Topic & cluster semantics (sanity)"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Confirm topic settings:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Replication factor"}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"min.insync.replicas"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Ensure no silent changes from in-house Kafka defaults."}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(n.p,{children:"Packet travelling to CC has to cross more layers : flink TM node NIC, vpc routing layer, peering endpoint, CC ingress routing, the broker network stack. I am not fully aware of the exact network topology b/w flink jobs and the in-house Kafka, but it is reasonable to assume it was much closer in terms of network hops. Also, I believe there was no TLS overhead when flink jobs were talking with the in-house cluster.\nThis is not a capacity or throttling problem. This is usually manageable by tuning the client appropriately (batching, in flight reqs, idempotency, etc ). We have not had the opportunity to do this yet, partly because the kafka client version used by the job is fairly ancient."}),"\n",(0,r.jsx)(n.p,{children:"There are a few things I would like to test next. I think we are on the right track with the RCA \u2014 latency is the primary driver here.\nI would like to verify what the configured timeouts are for Flink checkpoints + whether EOS is enabled for the Kafka sink ( if so, what is the timeout ) + confirm there are no differences in topic configuration on CC compared to our in-house Kafka defaults. If possible, we should enable Kafka client debug logs in the flink job to get more clarity."})]})}function d(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>o});var s=i(6540);const r={},t=s.createContext(r);function l(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);